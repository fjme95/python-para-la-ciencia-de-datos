{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introducción a gensim.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMylZAbi26NelXAJzv8t+hB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjme95/python-para-la-ciencia-de-datos/blob/main/Semana%206/Introducci%C3%B3n_a_gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agw5SDH4beUc"
      },
      "source": [
        "# Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1yv_hiOpt_t"
      },
      "source": [
        "## Tokenización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aP1_B3nqb-Q"
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzoJwkeqaUYb"
      },
      "source": [
        "texto = 'Este es un texto de prueba. ¡Tiene puntuación, acentos y números 1, 2, 3! Este _token es algo raro'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIZiM1qprvMp"
      },
      "source": [
        "Con ```tokenize``` obtenemos el texto sin números ni signos de puntuación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvoBqwNqqe74",
        "outputId": "63fc9b32-4124-4780-a0b8-8e4e8b2f3a08"
      },
      "source": [
        "list(tokenize(texto, to_lower=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['este',\n",
              " 'es',\n",
              " 'un',\n",
              " 'texto',\n",
              " 'de',\n",
              " 'prueba',\n",
              " 'tiene',\n",
              " 'puntuación',\n",
              " 'acentos',\n",
              " 'y',\n",
              " 'números',\n",
              " 'este',\n",
              " '_token',\n",
              " 'es',\n",
              " 'algo',\n",
              " 'raro']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbQLZDW-r-Cr"
      },
      "source": [
        "```simple_preprocess``` agrega unas cuentas reglas a lo que se considera un token. Específicamente, no puede empezar con '_' y debe tener entre 2 y 15 letras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUtSMPrSafEW",
        "outputId": "15d01532-9911-4e67-cab9-8f429c83b501"
      },
      "source": [
        "simple_preprocess(texto)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['este',\n",
              " 'es',\n",
              " 'un',\n",
              " 'texto',\n",
              " 'de',\n",
              " 'prueba',\n",
              " 'tiene',\n",
              " 'puntuación',\n",
              " 'acentos',\n",
              " 'números',\n",
              " 'este',\n",
              " 'es',\n",
              " 'algo',\n",
              " 'raro']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzw5Lak6sU48"
      },
      "source": [
        "El parámetro ```deacc = True``` elimina acentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWvbhl5eag02",
        "outputId": "2d070b8d-aed7-45c0-ca99-e6c4ee115da0"
      },
      "source": [
        "simple_preprocess(texto, deacc = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['este',\n",
              " 'es',\n",
              " 'un',\n",
              " 'texto',\n",
              " 'de',\n",
              " 'prueba',\n",
              " 'tiene',\n",
              " 'puntuacion',\n",
              " 'acentos',\n",
              " 'numeros']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyA5bvZBsc0U"
      },
      "source": [
        "Podemos tokenizar varios documentos con list comprehension. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_NBQ2RGrFOw"
      },
      "source": [
        "docs = [\n",
        "        '¡Primer documento!', \n",
        "        \"Este es el segundo documento.\", \n",
        "        'Este es el tercer documento, con un poco más de texto que los demás.'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY-9Czl1rSV3",
        "outputId": "8424d178-8a8b-495d-f924-f6230ab6d25f"
      },
      "source": [
        "tokenized_docs = [simple_preprocess(doc, deacc = True) for doc in docs]\n",
        "tokenized_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['primer', 'documento'],\n",
              " ['este', 'es', 'el', 'segundo', 'documento'],\n",
              " ['este',\n",
              "  'es',\n",
              "  'el',\n",
              "  'tercer',\n",
              "  'documento',\n",
              "  'con',\n",
              "  'un',\n",
              "  'poco',\n",
              "  'mas',\n",
              "  'de',\n",
              "  'texto',\n",
              "  'que',\n",
              "  'los',\n",
              "  'demas']]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY9MXm4vwLb3"
      },
      "source": [
        "¿Cómo eliminar stopwords con estas funciones?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSCgTSfProXt"
      },
      "source": [
        "## Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjj4wi6PubTc"
      },
      "source": [
        "gensim tiene una clase llamada ```Dictionary``` cuya utilidad principal es la de asignar un id a cada palabra y crear el corpus para entrenar los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MELYx2H-u9M2"
      },
      "source": [
        "from gensim import corpora"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyTcpq2rvHSi",
        "outputId": "f4e04d26-9835-4bd0-f492-486ea5079bba"
      },
      "source": [
        "dictionary = corpora.Dictionary([simple_preprocess(doc, deacc = True) for doc in docs])\n",
        "print(dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(16 unique tokens: ['documento', 'primer', 'el', 'es', 'este']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r6pEuVVvTsZ",
        "outputId": "da000030-82ac-46e4-af6e-f793ca273d92"
      },
      "source": [
        "dictionary.token2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'con': 6,\n",
              " 'de': 7,\n",
              " 'demas': 8,\n",
              " 'documento': 0,\n",
              " 'el': 2,\n",
              " 'es': 3,\n",
              " 'este': 4,\n",
              " 'los': 9,\n",
              " 'mas': 10,\n",
              " 'poco': 11,\n",
              " 'primer': 1,\n",
              " 'que': 12,\n",
              " 'segundo': 5,\n",
              " 'tercer': 13,\n",
              " 'texto': 14,\n",
              " 'un': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r5zDXwzvaxU"
      },
      "source": [
        "Podemos agregar documentos a nuestro a diccionario ocupando la función ```add_documents```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPqZr-OvqiK",
        "outputId": "95bee287-b3e3-464d-e88a-7c7279e3a309"
      },
      "source": [
        "docs_2 = [\n",
        "          'Este es otro documento que no estaba', \n",
        "          'Aparecerá la palabra taquito por este documento'\n",
        "]\n",
        "\n",
        "dictionary.add_documents([simple_preprocess(doc, deacc = True) for doc in docs_2])\n",
        "print(dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(25 unique tokens: ['documento', 'primer', 'el', 'es', 'este']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt8Wawwuv9s3",
        "outputId": "e1b6ee6d-4dbb-4f51-80fc-033e3379d62b"
      },
      "source": [
        "dictionary.token2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aparecera': 24,\n",
              " 'aparecerá': 19,\n",
              " 'con': 6,\n",
              " 'de': 7,\n",
              " 'demas': 8,\n",
              " 'documento': 0,\n",
              " 'el': 2,\n",
              " 'es': 3,\n",
              " 'estaba': 16,\n",
              " 'este': 4,\n",
              " 'la': 20,\n",
              " 'los': 9,\n",
              " 'mas': 10,\n",
              " 'no': 17,\n",
              " 'otro': 18,\n",
              " 'palabra': 21,\n",
              " 'poco': 11,\n",
              " 'por': 22,\n",
              " 'primer': 1,\n",
              " 'que': 12,\n",
              " 'segundo': 5,\n",
              " 'taquito': 23,\n",
              " 'tercer': 13,\n",
              " 'texto': 14,\n",
              " 'un': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8dldvm9wwiy"
      },
      "source": [
        "## Bolsa de Palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxRETH2Tw4v1"
      },
      "source": [
        "Para crear la bolsa de palabras basta que usamos la función ```doc2bow```. \n",
        "\n",
        "La función espera un documento tokenizado y regresa una lista con tuplas (word_id, word_count).\n",
        "\n",
        "Es muy parecido a ```skelarn.feature_extraction.text.CountVectorizer```. Crear el diccionario es lo equivalente a usar el método ```fit``` y ```doc2bow``` es equivalente a ```transform```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ef7HDwjxL4r",
        "outputId": "5570743c-5a56-40c9-f7f8-1fe3f876b693"
      },
      "source": [
        "corpus = [dictionary.doc2bow(doc) for doc in [simple_preprocess(doc) for doc in docs + docs_2]]\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1)],\n",
              " [(0, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
              " [(0, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (9, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (13, 1),\n",
              "  (14, 1),\n",
              "  (15, 1)],\n",
              " [(0, 1), (3, 1), (4, 1), (12, 1), (16, 1), (17, 1), (18, 1)],\n",
              " [(0, 1), (4, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE6pDrBeyl24"
      },
      "source": [
        "Para hacerlo claro para nosotros, podemos imprimir la palabra en lugar del id de la siguiente manera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTHHprNSysVM",
        "outputId": "591c33dc-8d23-4fbf-8304-5fd2c0025fde"
      },
      "source": [
        "[[(id, dictionary[id], count) for id, count in doc] for doc in corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 'documento', 1), (1, 'primer', 1)],\n",
              " [(0, 'documento', 1),\n",
              "  (2, 'el', 1),\n",
              "  (3, 'es', 1),\n",
              "  (4, 'este', 1),\n",
              "  (5, 'segundo', 1)],\n",
              " [(0, 'documento', 1),\n",
              "  (2, 'el', 1),\n",
              "  (3, 'es', 1),\n",
              "  (4, 'este', 1),\n",
              "  (6, 'con', 1),\n",
              "  (7, 'de', 1),\n",
              "  (9, 'los', 1),\n",
              "  (11, 'poco', 1),\n",
              "  (12, 'que', 1),\n",
              "  (13, 'tercer', 1),\n",
              "  (14, 'texto', 1),\n",
              "  (15, 'un', 1)],\n",
              " [(0, 'documento', 1),\n",
              "  (3, 'es', 1),\n",
              "  (4, 'este', 1),\n",
              "  (12, 'que', 1),\n",
              "  (16, 'estaba', 1),\n",
              "  (17, 'no', 1),\n",
              "  (18, 'otro', 1)],\n",
              " [(0, 'documento', 1),\n",
              "  (4, 'este', 1),\n",
              "  (19, 'aparecerá', 1),\n",
              "  (20, 'la', 1),\n",
              "  (21, 'palabra', 1),\n",
              "  (22, 'por', 1),\n",
              "  (23, 'taquito', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-N0a1xazAtu",
        "outputId": "47ea65cb-dd9d-42c1-fb5c-583f02c951d3"
      },
      "source": [
        "docs + docs_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['¡Primer documento!',\n",
              " 'Este es el segundo documento.',\n",
              " 'Este es el tercer documento, con un poco más de texto que los demaś.',\n",
              " 'Este es otro documento que no estaba',\n",
              " 'Aparecerá la palabra taquito por este documento']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZVGzbeAzGtf",
        "outputId": "95efc26a-c0f6-432a-dbc5-42d9c99860a2"
      },
      "source": [
        "dictionary.doc2bow(simple_preprocess('Es mejor comer un taquito al día que ningún taquito'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 1), (12, 1), (15, 1), (23, 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urYB4TO7ze6V"
      },
      "source": [
        "## Salvar el diccionario y el corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM7ZPMs7zjhJ"
      },
      "source": [
        "dictionary.save('dictionary.dict')\n",
        "corpora.MmCorpus.serialize('bow_corpus.mm', corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udy-62170MMF"
      },
      "source": [
        "loaded_dict = corpora.Dictionary.load('dictionary.dict')\n",
        "loaded_corpus = corpora.MmCorpus('bow_corpus.mm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMGOcJrS0kbK",
        "outputId": "a2414894-c29f-4413-9f5c-fd626be24468"
      },
      "source": [
        "list(loaded_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1.0), (1, 1.0)],\n",
              " [(0, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0)],\n",
              " [(0, 1.0),\n",
              "  (2, 1.0),\n",
              "  (3, 1.0),\n",
              "  (4, 1.0),\n",
              "  (6, 1.0),\n",
              "  (7, 1.0),\n",
              "  (9, 1.0),\n",
              "  (11, 1.0),\n",
              "  (12, 1.0),\n",
              "  (13, 1.0),\n",
              "  (14, 1.0),\n",
              "  (15, 1.0)],\n",
              " [(0, 1.0), (3, 1.0), (4, 1.0), (12, 1.0), (16, 1.0), (17, 1.0), (18, 1.0)],\n",
              " [(0, 1.0), (4, 1.0), (19, 1.0), (20, 1.0), (21, 1.0), (22, 1.0), (23, 1.0)]]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF7-KCQM0rgq"
      },
      "source": [
        "## TfIdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbHs1zM61zKX"
      },
      "source": [
        "Para crear la BoW con tfidf usamos ```gensim.models.TfidfModel```. Haciendo la comparación con sklearn, es como si primero ocuparamos un ```CountVectorizer``` y luego un ```TfidfTransformer```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f43OCdoo0uie"
      },
      "source": [
        "from gensim import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PL_x6O80xWk",
        "outputId": "503c88f7-759e-4e39-cf85-425527c95ade"
      },
      "source": [
        "tfidf = models.TfidfModel(corpus = loaded_corpus)\n",
        "tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.tfidfmodel.TfidfModel at 0x7f7638a6ef90>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LpW_mXO1BnT",
        "outputId": "80f4b0e4-d448-4edd-8add-16161288ac7a"
      },
      "source": [
        "tfidf[corpus[0]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLOMX71U1YD9",
        "outputId": "66a20ecb-7708-4354-d51c-363fddf826c6"
      },
      "source": [
        "tfidf[corpus[1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 0.4737637094387418),\n",
              " (3, 0.26411992828600717),\n",
              " (4, 0.11537529839652863),\n",
              " (5, 0.8321521204809549)]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJL4L4gw2IWb"
      },
      "source": [
        "El modelo de TfIdf ya no consideró la palabra con id 0 (documento)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ-l2tPVhBjQ"
      },
      "source": [
        "## word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWK-SU0hXYW"
      },
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEp7tu5uCGV8"
      },
      "source": [
        "### Modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwJhLtRpjTxA",
        "outputId": "019ab933-4a18-4cb9-a397-d70a29ff4ec9"
      },
      "source": [
        "# api.info()\n",
        "api.info('glove-wiki-gigaword-50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n",
              " 'checksum': 'c289bc5d7f2f02c6dc9f2f9b67641813',\n",
              " 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n",
              " 'file_name': 'glove-wiki-gigaword-50.gz',\n",
              " 'file_size': 69182535,\n",
              " 'license': 'http://opendatacommons.org/licenses/pddl/',\n",
              " 'num_records': 400000,\n",
              " 'parameters': {'dimension': 50},\n",
              " 'parts': 1,\n",
              " 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.',\n",
              " 'read_more': ['https://nlp.stanford.edu/projects/glove/',\n",
              "  'https://nlp.stanford.edu/pubs/glove.pdf'],\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG6pl_LZ5R5N",
        "outputId": "e0b8e740-618d-4618-8e7b-82d9c6f8bd95"
      },
      "source": [
        "model = api.load('glove-wiki-gigaword-50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIuCHhoXCIQf"
      },
      "source": [
        "#### Palabras similares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVCmFJ2p5zdn",
        "outputId": "811e888b-b349-4008-b4e5-6bc4a5ce4f13"
      },
      "source": [
        "model.most_similar('mexico')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mexican', 0.8550674319267273),\n",
              " ('venezuela', 0.8496899008750916),\n",
              " ('colombia', 0.8490317463874817),\n",
              " ('peru', 0.8446482419967651),\n",
              " ('chile', 0.8439290523529053),\n",
              " ('puerto', 0.8362628221511841),\n",
              " ('rico', 0.8194695711135864),\n",
              " ('cuba', 0.8125205636024475),\n",
              " ('guatemala', 0.8113811016082764),\n",
              " ('panama', 0.8096755743026733)]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aet8WaxR5_Hk",
        "outputId": "3c468afd-b6c3-4246-d062-6e365ebded82"
      },
      "source": [
        "print(model.similarity('mexico', 'mariachi'))\n",
        "print(model.similarity('usa', 'mariachi'))\n",
        "print(model.similarity('alemania', 'mariachi'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3073805\n",
            "0.07876266\n",
            "-0.014929158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4bms-8ACLs5"
      },
      "source": [
        "#### Encontrar el valor extraño en un conjunto de valores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "qfe7bIYv6TRo",
        "outputId": "89a56579-1d72-457b-9d68-802e95aac6d7"
      },
      "source": [
        "model.doesnt_match(['guitar', 'violin', 'piano', 'tablet'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tablet'"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "zVrTYzmZ7r1J",
        "outputId": "a88387bf-4ebb-4bad-946e-741f6d24c45f"
      },
      "source": [
        "model.doesnt_match(['guitar', 'violin', 'piano', 'drums'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drums'"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV9eCgLBCXV-"
      },
      "source": [
        "#### Analogías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBowHYO1BFTN",
        "outputId": "9e34f5e5-c3b7-4eed-8ed6-dd6c77e48854"
      },
      "source": [
        "model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.8523603677749634),\n",
              " ('throne', 0.7664334177970886),\n",
              " ('prince', 0.759214460849762),\n",
              " ('daughter', 0.7473883032798767),\n",
              " ('elizabeth', 0.7460220456123352),\n",
              " ('princess', 0.7424569725990295),\n",
              " ('kingdom', 0.7337411642074585),\n",
              " ('monarch', 0.7214490175247192),\n",
              " ('eldest', 0.7184861898422241),\n",
              " ('widow', 0.7099430561065674)]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xtmF-cJBZV5",
        "outputId": "a3b48e9a-3070-4deb-8e9f-7c419c3c10e0"
      },
      "source": [
        "model.most_similar(positive=['car', 'air'], negative=['road'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('jet', 0.7882938385009766),\n",
              " ('airplane', 0.7694613933563232),\n",
              " ('aircraft', 0.7238950133323669),\n",
              " ('planes', 0.7226904630661011),\n",
              " ('plane', 0.7093905806541443),\n",
              " ('pilot', 0.707859992980957),\n",
              " ('airplanes', 0.702531099319458),\n",
              " ('pilots', 0.6944992542266846),\n",
              " ('c-130', 0.67693030834198),\n",
              " ('fighter', 0.6713298559188843)]"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we1fb1FCBh0R",
        "outputId": "9c7093e3-f78b-4558-e47f-c17ca66f54b9"
      },
      "source": [
        "model.most_similar(positive=['lawyer', 'medicine'], negative=['justice'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('physician', 0.7534809112548828),\n",
              " ('medical', 0.7412653565406799),\n",
              " ('dentist', 0.7200738191604614),\n",
              " ('pediatrician', 0.7030641436576843),\n",
              " ('nursing', 0.6904869675636292),\n",
              " ('cardiologist', 0.6887562274932861),\n",
              " ('pharmacist', 0.6869213581085205),\n",
              " ('internist', 0.6854752898216248),\n",
              " ('clinic', 0.6843182444572449),\n",
              " ('veterinary', 0.6726669669151306)]"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWZXNHvkDMOA"
      },
      "source": [
        "### Entrenar un modelo propio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKlFYHIPDPbz"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/archive.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/friends_dataset/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW_Yfm9WEPQx"
      },
      "source": [
        "#https://datascience.stackexchange.com/questions/11077/using-several-documents-with-word2vec\n",
        "import os\n",
        "\n",
        "class WordTrainer(object):\n",
        "   def __init__(self, dir_name):\n",
        "      self.dir_name = dir_name\n",
        "   def __iter__(self):\n",
        "      for _,file_name in enumerate(os.listdir(self.dir_name)):\n",
        "          for _,line in enumerate(open(os.path.join(self.dir_name, file_name),'r')):\n",
        "              words = simple_preprocess(line)\n",
        "              yield words\n",
        "\n",
        "screen_play = WordTrainer('/content/friends_dataset')\n",
        "my_model = Word2Vec(screen_play, size=300, window=15, min_count=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-RTbJ5OFBtJ",
        "outputId": "7418b403-c3ad-4b5d-a456-8e44bfbed231"
      },
      "source": [
        "my_model.wv.most_similar('ross')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('joey', 0.7847803831100464),\n",
              " ('chandler', 0.7796059846878052),\n",
              " ('rachel', 0.7070483565330505),\n",
              " ('phoebe', 0.6731643676757812),\n",
              " ('monica', 0.6516903638839722),\n",
              " ('tag', 0.6110426187515259),\n",
              " ('richard', 0.6073410511016846),\n",
              " ('paul', 0.5925347805023193),\n",
              " ('pete', 0.5805870294570923),\n",
              " ('mike', 0.57646244764328)]"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "F-TTMuuFFz7s",
        "outputId": "2b1e6bdf-2d11-4117-a694-c7508223e046"
      },
      "source": [
        "my_model.wv.doesnt_match(['rachel', 'ross', 'phoebe', 'chandler', 'joey'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'joey'"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75avbuhLH9qO",
        "outputId": "9718b298-3e57-4add-ee31-e666ce00e90f"
      },
      "source": [
        "my_model.wv.most_similar(['ross', 'actor'], ['paleontologist'], topn=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('but', 0.5867981910705566),\n",
              " ('because', 0.5396002531051636),\n",
              " ('that', 0.5296133756637573),\n",
              " ('big', 0.5232568979263306),\n",
              " ('cause', 0.5188854336738586),\n",
              " ('mean', 0.5145672559738159),\n",
              " ('thing', 0.5111375451087952),\n",
              " ('just', 0.5063825845718384),\n",
              " ('person', 0.5029212236404419),\n",
              " ('pause', 0.49938642978668213),\n",
              " ('important', 0.4991603195667267),\n",
              " ('chandler', 0.48641732335090637),\n",
              " ('joey', 0.481323778629303),\n",
              " ('though', 0.4758177697658539),\n",
              " ('more', 0.47416940331459045),\n",
              " ('stupid', 0.47282907366752625),\n",
              " ('than', 0.47001761198043823),\n",
              " ('reason', 0.46713393926620483),\n",
              " ('it', 0.4650190770626068),\n",
              " ('idea', 0.46199238300323486)]"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    }
  ]
}