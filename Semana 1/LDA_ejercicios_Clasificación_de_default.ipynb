{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA - Clasificación de default.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUE51syizUt0qVOzplaOxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjme95/python-para-la-ciencia-de-datos/blob/main/Semana%201/LDA_ejercicios_Clasificaci%C3%B3n_de_default.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug-edvhJdPNd"
      },
      "source": [
        "# Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1RnfmlvgOoz"
      },
      "source": [
        "%%capture\n",
        "!pip install -U plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZExEarcxcDKh"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBneVnVbEF5l"
      },
      "source": [
        "sep= \"\\n-------------------\\n\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kwgnQYUdRaf"
      },
      "source": [
        "# Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U7oCh8rEZRT"
      },
      "source": [
        "Trabajaremos con datos del Lending Club.\n",
        "\n",
        "Lending Club es una plataforma de préstamos entre pares (P2P), donde los prestatarios envían sus solicitudes de préstamo y los prestamistas individuales seleccionan las solicitudes que desean financiar. Los prestatarios reciben el monto total del préstamo emitido menos la tarifa inicial, que se paga a la empresa. Los inversores compran notas respaldadas por préstamos personales y pagan a Lending Club una tarifa de servicio.\n",
        "\n",
        "Los préstamos P2P reducen el costo de los préstamos personales en comparación con el financiamiento tradicional al conectar directamente a los prestatarios e inversores. Sin embargo, siempre existe el riesgo de invertir en un préstamo incobrable. De hecho, la tasa de incumplimiento de los préstamos P2P es mucho más alta que la de los préstamos tradicionales. Por lo tanto, la industria crediticia está muy interesada en brindar a los inversionistas una evaluación integral del riesgo de las solicitudes de préstamo. La empresa comparte datos sobre todas las solicitudes de préstamos realizadas a través de su plataforma.\n",
        "\n",
        "La descripción de las variables en el dataset se puede descargar [aqui](http://www-2.rotman.utoronto.ca/~hull/mlbook/lendingclub_datadictionary.xlsx).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43HnzIhZO4K6"
      },
      "source": [
        "!mkdir data\n",
        "!wget http://www-2.rotman.utoronto.ca/~hull/mlbook/lending_clubFull_Data_Set.xlsx -O data/lending_club.xlsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6B1yKWBchIu"
      },
      "source": [
        "data_raw = pd.read_excel(\"data/lending_club.xlsx\", index_col=0)\n",
        "data_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTLvn514dWSt"
      },
      "source": [
        "## Datos Faltantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeZ1oXPqhlKN"
      },
      "source": [
        "# DataFrame o Series en la que aparezca el número de datos faltantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moYw6p95u6AY"
      },
      "source": [
        "px.bar(na_values, \"index\", \"n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODL46T69GJp"
      },
      "source": [
        "data_filt = data_raw.loc[:, data_raw.columns[na_values.n < .1]]\n",
        "data_filt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7LNVkXmAN7c"
      },
      "source": [
        "print(\"Datos originales\\n\")\n",
        "print(data_raw.dtypes.value_counts())\n",
        "print(sep)\n",
        "print(\"Datos filtrado\\n\")\n",
        "data_filt.dtypes.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGP65BqzdkIB"
      },
      "source": [
        "## División del dataset en entrenamiento y pruebas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9y5Ru1HtzE9"
      },
      "source": [
        "data_filt.loan_status.value_counts(dropna = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Wsm4mEtd-y"
      },
      "source": [
        "loan_status_to_objective = {\n",
        "    \"Current\": 0, \n",
        "    \"Fully Paid\": 0, \n",
        "    \"Charged Off\": 1, \n",
        "    \"Late (31-120 days)\": 0, \n",
        "    \"In Grace Period\": 0, \n",
        "    \"Late (16-30 days)\": 0,  \n",
        "    \"Default\": 1, \n",
        "}\n",
        "\n",
        "X = data_filt.drop('loan_status', 1)\n",
        "y = data_filt.loan_status.map(loan_status_to_objective)\n",
        "\n",
        "X = X[~y.isna()]\n",
        "y = y[~y.isna()]\n",
        "print(X.shape, y.shape)\n",
        "y.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYmw8hB9urzG"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .7, random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_lJniuQprg6"
      },
      "source": [
        "# Análisis de las variables por tipo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJaF2oAjCzl8"
      },
      "source": [
        "columns_by_type = {k.name: v for k, v in X.columns.to_series().groupby(data_filt.dtypes).groups.items()}\n",
        "pprint(columns_by_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1dHjdtOKnDk"
      },
      "source": [
        "X.select_dtypes('float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2fvwRD2eqbj"
      },
      "source": [
        "## Variables Numéricas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHTO8l3gd_iZ"
      },
      "source": [
        "### Variables con poca variación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Toh8mfs6ER"
      },
      "source": [
        "var_filter = VarianceThreshold(threshold=.90)\n",
        "var_filter.fit(X_train[columns_by_type['float64']])\n",
        "constant_columns = [column for column in X_train[columns_by_type['float64']].columns\n",
        "                    if column not in X_train[columns_by_type['float64']].columns[var_filter.get_support()]]\n",
        "constant_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARfSfk92vnf3"
      },
      "source": [
        "X_train.drop(columns=constant_columns, inplace=True)\n",
        "X_test.drop(columns=constant_columns, inplace=True)\n",
        "\n",
        "columns_by_type['float64'] = columns_by_type['float64'].drop(constant_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIemy5rSeuvZ"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "data_num_sc = pd.DataFrame(scaler.fit_transform(X_train[columns_by_type['float64']]), columns = X_train[columns_by_type['float64']].columns, index = X_train[columns_by_type['float64']].index)\n",
        "data_num_sc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fANy62qIeDzZ"
      },
      "source": [
        "### Variables con alta correlación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5AIh_CXlNU5"
      },
      "source": [
        "numeric_to_remove = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y72ph2EmeIq-"
      },
      "source": [
        "# Graficar la matriz de correlación de las variables de tipo float64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw1e0o1ikgkZ"
      },
      "source": [
        "correlated_features = set()\n",
        "for i in range(len(corr_df.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(corr_df.iloc[i, j]) > 0.7:\n",
        "            colname = corr_df.columns[i]\n",
        "            correlated_features.add(colname)\n",
        "len(correlated_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x51beCHyQIF"
      },
      "source": [
        "correlated_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMWxUxq6ykiQ"
      },
      "source": [
        "X_train.drop(columns=correlated_features, inplace=True)\n",
        "X_test.drop(columns=correlated_features, inplace=True)\n",
        "\n",
        "data_num_sc.drop(columns=correlated_features, inplace=True)\n",
        "columns_by_type['float64'] = columns_by_type['float64'].drop(correlated_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjDctPgReCBb"
      },
      "source": [
        "\n",
        "## Fechas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SBjwXUMeOFj"
      },
      "source": [
        "Las fechas no las ocuparemos a menos en este análisis. Aunque cabe destacar que podrían ocupar si se transforman a otro tipo de dato (e.g. crear \"número de días desde...\" y obtener la nueva variable usando una diferencia en días entre fechas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdGmNKlEDWeQ"
      },
      "source": [
        "for col in columns_by_type[\"datetime64[ns]\"]:\n",
        "    print(data_filt[col].head(), sep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELzl8n0pE4Tu"
      },
      "source": [
        "X_train.drop(columns=columns_by_type[\"datetime64[ns]\"], inplace=True)\n",
        "X_test.drop(columns=columns_by_type[\"datetime64[ns]\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu3lqFY30k41"
      },
      "source": [
        "## Factores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CARA2GLTeuxQ"
      },
      "source": [
        "Para poder usar factores en el modelo, es mecesario convertirlas a variables dummies. Esto es, considerando la siguiente variable:\n",
        "\n",
        "estado_civil|\n",
        "------------|\n",
        "soltero\n",
        "casado\n",
        "soltero\n",
        "soltero\n",
        "viudo\n",
        "\n",
        "Al obtener las variables dummies de esta obtendriamos:\n",
        "\n",
        "estado_civil_soltero|estado_civil_casado|estado_civil_viudo\n",
        "---|---|---\n",
        "1|0|0\n",
        "0|1|0\n",
        "1|0|0\n",
        "1|0|0\n",
        "0|0|1\n",
        "\n",
        "Incluso se puede quitar uno de los niveles y dejarlo como el estado base:\n",
        "\n",
        "estado_civil_casado|estado_civil_viudo\n",
        "---|---\n",
        "0|0\n",
        "1|0\n",
        "0|0\n",
        "0|0\n",
        "0|1\n",
        "\n",
        "\n",
        "Si nuestra variable tiene muchos niveles, el crear variables dummies de esta puede hacer que nuestro dataset crezca en dimensión, complicando el entrenamiento del modelo. Para estos casos, se puede buscar la posibilidad de unir distintos niveles en uno sólo o eliminar la variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Baj2rJe3eeGF"
      },
      "source": [
        "unique_values_by_column = X_train[columns_by_type[\"object\"]].nunique().reset_index(name = \"n\")\n",
        "unique_values_by_column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtR59ABnfzY0"
      },
      "source": [
        "px.bar(data_frame = unique_values_by_column, \n",
        "       x =\"index\", \n",
        "       y = \"n\", \n",
        "       title=\"Cantidad de niveles por factor\", \n",
        "       labels={\n",
        "           \"index\": \"Nombre de la variable\",\n",
        "           \"n\": \"Número de niveles\"\n",
        "           }\n",
        "       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wGVT_RipEL"
      },
      "source": [
        "Eliminamos las variables con más de 900 niveles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFdsH6zyfWww"
      },
      "source": [
        "drop_columns = columns_by_type[\"object\"][unique_values_by_column.n > 900].to_list()\n",
        "drop_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1vRlDZe2lfv"
      },
      "source": [
        "X_train.drop(columns=drop_columns, inplace=True)\n",
        "X_test.drop(columns=drop_columns, inplace=True)\n",
        "\n",
        "columns_by_type['object'] = columns_by_type['object'].drop(drop_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4X7QtHZkUEE"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHg29Yo-nHHk"
      },
      "source": [
        " X_train = pd.get_dummies(X_train, columns=columns_by_type['object'])\n",
        " X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSvi6AhhPIhO"
      },
      "source": [
        "# Imputación de datos faltantes\n",
        "\n",
        "Como los modelos matemáticos no trabajan con valores faltantes, es necesario aplicar un tratamiento a estos, ya sea eliminando los casos o imputándolos. Para imputarlos podemos optar por métodos sencillos (media, mediana o moda de la variable) o ir por métodos un poco más elaborados (Multiple Imputation by Chained Equations, KNN, Exact Matrix Completion via Convex Optimization, etc.). \n",
        "\n",
        "Lo recomendable es hacer un análisis de los datos faltantes por variable antes de pensar en imputar los datos (ver: [To impute or not to impute?](https://towardsdatascience.com/to-impute-or-not-to-impute-a-practical-example-when-imputation-could-lead-to-wrong-conclusions-fd1e340d779a)).\n",
        "\n",
        "En este caso, imputamos los valores faltantes en nuestro dataset de la manera más ingenua posible. Ponemos 99 en todos los valores faltantes. En los ejercicios vamos a pensar un poco sobre las implicaciones de esta imputación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-3zQtZV4cMc"
      },
      "source": [
        "X_train_fact = X_train.fillna(99).drop(\"id\", 1)\n",
        "X_train_fact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbaaxbKbltfa"
      },
      "source": [
        "px.bar(pd.concat([X_train_fact, y_train], 1).corr()['loan_status'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXVW-74bmwTB"
      },
      "source": [
        "data_plot = pd.concat([X_train_fact, y_train], 1)\n",
        "data_plot.loan_status = data_plot.loan_status + np.random.normal(0, .1, len(data_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFIEQ8X2naA1"
      },
      "source": [
        "px.scatter(data_frame = data_plot, x = 'loan_status', y = 'last_fico_range_high', opacity = .5, title = 'last_fico_range_high vs. loan_status <br><span>Tiene ruido para facilitar la visualización</span>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOFu3M_UizqP"
      },
      "source": [
        "# Latent Discriminant Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv9Jv-L0V_Yx"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6QI6Z4biwhl"
      },
      "source": [
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train_fact, y_train)\n",
        "train_pred = lda.predict(X_train_fact)\n",
        "print(classification_report(y_train, train_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sooUYSsdu_2W"
      },
      "source": [
        "Imaginemos que nuestro vector de etiquetas se ve así (0, 1, 1, 0, 1), estas son las etiquetas **reales**, y que el vector de **predicciones** se ve así (0, 0, 1, 0, 0).\n",
        "\n",
        "real: (0, 1, 1, 0, 1) \\\n",
        "pred: (0, 0, 1, 0, 0)\n",
        "\n",
        "\n",
        "La matriz de confusión para este caso se vería de la siguiente manera\n",
        "\n",
        "*|1|0|\n",
        "-|-|-|\n",
        "**1**|1|2|\n",
        "**0**|0|2|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vjt00QtrLHI"
      },
      "source": [
        "*| no me pago (1) | me pago (0)\n",
        "-----|-|-|\n",
        "no me pago (1) | 1332 | 470\n",
        "me pago (0) | 526 | 15148"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI-XnJLrqjr9"
      },
      "source": [
        "confusion_matrix(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6QMk8YVV9uK"
      },
      "source": [
        "## Prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m250cdM8zxCP"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em1H0U5UimHa"
      },
      "source": [
        "X_test_fact = pd.get_dummies(X_test, columns=columns_by_type['object']).fillna(99)\n",
        "X_test_fact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0OpM-nGi2aB"
      },
      "source": [
        "missing_cols = set( X_train_fact.columns ) - set( X_test_fact.columns )\n",
        "missing_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUGkbohzi92L"
      },
      "source": [
        "for c in missing_cols:\n",
        "    X_test_fact[c] = 0\n",
        "X_test_fact = X_test_fact[X_train_fact.columns]\n",
        "X_test_fact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ASx8K-YjRb4"
      },
      "source": [
        "test_pred = lda.predict(X_test_fact)\n",
        "print(classification_report(y_test, test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vxp94vb1lCa"
      },
      "source": [
        "print(classification_report(y_train, train_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAQlkcV4i-ok"
      },
      "source": [
        "Comparación de precisión obtenida en el set de entrenamiento y el set de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYt_DxQAjcPJ"
      },
      "source": [
        "print(\n",
        "    lda.score(X_train_fact, y_train), \n",
        "    lda.score(X_test_fact, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU-06epkwkB9"
      },
      "source": [
        "## ¿Cómo afecta cada variable?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRyMwdgywt5y"
      },
      "source": [
        "coef_df = pd.DataFrame(lda.coef_[0], X_train_fact.columns, [\"coef_\"])\n",
        "print(lda.intercept_)\n",
        "coef_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFG8bcT7xIGc"
      },
      "source": [
        "px.bar(coef_df.reset_index(), 'coef_', 'index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlbzcFpm2-q9"
      },
      "source": [
        "X_test.loan_amnt * 10e-6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUn6HVa_zURG"
      },
      "source": [
        "y_train[train_pred == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc7WgZ0MzXKm"
      },
      "source": [
        "np.dot(lda.coef_, X_train_fact.loc[9377, :]) + lda.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvyx7os5zitu"
      },
      "source": [
        "y_train[train_pred == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssEkIHCkzk20"
      },
      "source": [
        "np.dot(lda.coef_, X_train_fact.loc[14719, :]) + lda.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9FFq3r9jFpn"
      },
      "source": [
        "## LDA para reducir dimensión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wx-6KF35Ez2"
      },
      "source": [
        "X_proj = lda.transform(X_train_fact)\n",
        "X_proj.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggwzM6KI4nyq"
      },
      "source": [
        "X_proj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VgVqXlsCMwf"
      },
      "source": [
        "probs = lda.predict_proba(X_train_fact)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asRQfkJ75DfH"
      },
      "source": [
        "probs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITpVZ1DpCc2q"
      },
      "source": [
        "tol = 1e-3\n",
        "for i, p in enumerate(probs):\n",
        "    if .5-tol < p[0] < .5 + tol:\n",
        "        print(i, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbQ77CRTDCCg"
      },
      "source": [
        "line = X_proj[4558]\n",
        "line[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnZJCFDg5czk"
      },
      "source": [
        "fig = px.scatter()\n",
        "fig.add_scatter(x = X_proj[y_train == 0, 0], y = np.random.rand(len(X_proj[y_train==0])), mode = \"markers\", opacity=.5, name = \"normal\")\n",
        "fig.add_scatter(x = X_proj[y_train == 1, 0], y = np.random.rand(len(X_proj[y_train==1])), mode = \"markers\", opacity = .5, name = \"default\")\n",
        "fig.add_vline(x = line[0], line_dash = 'dash')\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Reducción de la dimensión de LDA\",\n",
        "    xaxis_title=\"LDA1<br><sup>Pese a que los datos se muestran en dos dimensiones, la proyección sólo fue a una (= n_clases - 1)<br>Se agrego aleatoriedad al eje y para facilitar la visualización</sup>\",\n",
        "    legend_title=\"Etiqueta\",\n",
        "    font=dict(\n",
        "        size=18\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm9xqYe1XM8U"
      },
      "source": [
        "# Ejercicios\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHKbWZ5bdvyD"
      },
      "source": [
        "## Factores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pxYN6gfdzwv"
      },
      "source": [
        "### Condensar niveles\n",
        "\n",
        "Condensar niveles de factores usualmente es antecedido por un análisis por variable comparando la relación entre cada nivel, la variable de respuesta (en este caso ```loan_status```) y otras covariables. De este modo, niveles que aparentan tener la misma relación con la variable de respuesta pueden juntarse en uno solo; Algunas veces, mejorando el desempeño del modelo y reduciendo la dimensionalidad (y con esto el tiempo de cómputo en algunos casos).\n",
        "\n",
        "Sin embargo, si se tiene una gran cantidad de factores como covariables y estos a su vez tienen muchos niveles, puede llegar a ser un trabajo arduo que no compense la mejora obtenida en el desempeño del modelo o la rapidez del entrenamiento.\n",
        "\n",
        "Para este ejercicio, use su intuición en lugar de hacer estas comparaciones. Tampoco es necesario considerar todos los factores, con una cantidad pequeña (por ejemplo, a lo más 3) es suficiente.\n",
        "\n",
        "1. Condense los niveles de factores que usted considere pueden pertenecer a uno sólo. Puede comenzar con la variable ```home_ownership```, condensando en un nivel llamado ```not_owned``` a todos los niveles que no son ```OWN```.\n",
        "2. Entrene LDA con estos cambios y compare los resultados obtenidos. ¿Mejoró el modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuMAhfkFXXNV"
      },
      "source": [
        "## Imputación (opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqUeGJkHaAyY"
      },
      "source": [
        "### Constante\n",
        "\n",
        "1. ¿Qué problemas tiene imputar un valor constante en todas las variables con datos faltantes? Piense en la escala de las variables\n",
        "    2. ¿Cómo afecta a la estandarización de las variables?\n",
        "    3. ¿Qué relación tiene con los outliers?\n",
        "2. ¿Por qué en este caso no presentó problemas aparentes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttyIZR5uXZwd"
      },
      "source": [
        "### Media, mediana y moda\n",
        "\n",
        "1. Cambiar la imputación realizada por la media, mediana y moda (tres ejercicios diferentes, realizando uno esta bien) y comparar los resultados obtenido con los vistos en el notebook.\n",
        "2. ¿Qué implica llenar los valores valores vacios con este tipo de valores? Tome como ejemplo la variable ```mths_since_last_delinq```, ¿qué asumimos de las personas que no han delinquido?\n",
        "\n",
        "Nota: Para familiarizarse con pandas, es un buen ejercicio realizarlo utilizando sólo pandas. Pero también puede utilizar [```sklearn.impute.SimpleImputer```](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apoILBBVY_mQ"
      },
      "source": [
        "### KNN (más opcional)\n",
        "\n",
        "1. Realice la imputación de los valores con KNN y compare los resultados obtenidos.\n",
        "2. ¿Cómo funciona esta imputación y qué implica para los valores perdidos?\n",
        "\n",
        "Nota: Puede usar la implementación realizada en [```fancyimpute```](https://github.com/iskandr/fancyimpute)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3FgZ9N5rAp4"
      },
      "source": [
        "# Ligas interesantes\n",
        "\n",
        "- [BASIC LITERACY OF STATISTICS — 3](https://medium.com/@yohoshiva1609/basic-literacy-of-statistics-3-bc9f5a69f116)\n",
        "- [Sobre la estandarización en variables dummies](https://stats.stackexchange.com/questions/463690/multiple-regression-with-mixed-continuous-categorical-variables-dummy-coding-s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTQIAlJU700P"
      },
      "source": [
        "## TODO\n",
        "\n",
        "- Agregar liga a matriz de confusion y metricas"
      ]
    }
  ]
}